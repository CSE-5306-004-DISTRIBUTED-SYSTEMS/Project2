# Project Assignment 2 Report

2258-CSE-5306-004  
Name:

- John Song - 10023064679
- Adam Emerson - 1000773509

Github: [https://github.com/CSE-5306-004-DISTRIBUTED-SYSTEMS/Project2.git](https://github.com/CSE-5306-004-DISTRIBUTED-SYSTEMS/Project2.git)

## 1. System Overview

This system allows users to create polls and vote, with the results being aggregated across the distributed nodes.  
This system is designed to allow for the creation and management of polls across multiple, distributed nodes. It focuses on reliability and real-time result aggregation

#### Five Functional Requirements

- Create Poll: A user can create a new poll with a question and a set of options.
- Cast Vote: A user can vote for an option on a specific poll.
- Get Poll Results: A user can view the current vote counts for a specific poll.
- List All Polls: A user can see a list of all available polls.
- Close Poll: The creator of a poll can close it to prevent further voting.

## System Designs

### 2.1 Resource Based Architecture w/ HTTP (REST API)

The REST-based architecture implements a distributed polling system using HTTP communication and a resource-oriented design. The system consists of 5 containerized nodes:

**System Components:**

- **Frontend (React)**: User interface built with TypeScript and Tailwind CSS, running on port 3002
- **Load Balancer (NGINX)**: Distributes incoming requests evenly between API instances on port 3005
- **API Instances (2x Hono)**: REST-based microservices handling business logic on internal port 3000
- **Database (PostgreSQL)**: Single database instance storing all poll data on port 5432

**Communication Model:** HTTP/REST with JSON payloads

- Client-server communication via standard HTTP methods (GET, POST, PUT)
- Stateless request-response pattern
- JSON serialization for data exchange
- Load balancing for horizontal scaling

**How it supports the five functional requirements:**

1. **Create Poll**: `POST /polls` endpoint with poll metadata in JSON format
2. **Cast Vote**: `POST /polls/{id}/votes` endpoint with vote data
3. **Get Poll Results**: `GET /polls/{id}/results` endpoint returning aggregated counts
4. **List All Polls**: `GET /polls` endpoint returning all available polls
5. **Close Poll**: `PUT /polls/{id}/close` endpoint for poll creators

**Architecture Benefits:**

- Simple HTTP-based communication with wide tooling support
- Horizontal scalability through load balancing
- Stateless design enabling easy scaling
- Standard REST conventions for predictable API design

### 2.2 Microservice gRPC

## 3. Evaluation

Performance (latency, throughput) & Scalability.

$Latency = T_{response} - T_{request}$.

$Throughput = \frac{Total \space Requests}{Latency} $

### 3.0 Hardware

Tests were conducted on a Macbook Pro with the M2 Pro chip and 16gb of ram.

### 3.1 Experiement (write-heavy scalability) - Voting

This test simulates multiple users casting votes in a poll at the same time.

#### REST HTTPS Evaluation

| Total Users | Scenario | Avg Latency (ms) | Throughput (req/s) |
| ----------- | -------- | ---------------- | ------------------ |
| 10          | Voting   | 30.01            | 249.60             |
| 50          | Voting   | 26.36            | 1175.28            |
| 100         | Voting   | 34.45            | 1615.69            |
| 500         | Voting   | 140.42           | 1895.35            |
| 1000        | Voting   | 225.59           | 2357.78            |

#### Microservice gRPC Evaluation

| Total Users | Scenario | Avg Latency (ms) | Throughput (req/s) |
| ----------- | -------- | ---------------- | ------------------ |
| 10          | Voting   | 16.98            | 510.52             |
| 50          | Voting   | 30.68            | 920.67             |
| 100         | Voting   | 56.80            | 848.71             |
| 500         | Voting   | 212.70           | 1073.58            |
| 1000        | Voting   | 352.02           | 1228.48            |

### 3.2 Experiement (read-heavy scalability) - Showing poll results

This test simulates multiple users accessing poll results at the same time.

#### REST HTTPS Evaluation (Table 1)

| Total Users | Scenario | Avg Latency (ms) | Throughput (req/s) |
| ----------- | -------- | ---------------- | ------------------ |
| 10          | Results  | 5.83             | 650.32             |
| 50          | Results  | 13.20            | 1919.89            |
| 100         | Results  | 18.87            | 2751.93            |
| 500         | Results  | 78.59            | 2866.68            |
| 1000        | Results  | 109.58           | 4043.72            |

#### Microservice gRPC Evaluation (Table 2)

| Total Users | Scenario | Avg Latency (ms) | Throughput (req/s) |
| ----------- | -------- | ---------------- | ------------------ |
| 10          | Results  | 11.85            | 695.41             |
| 50          | Results  | 22.83            | 1233.66            |
| 100         | Results  | 52.67            | 1001.24            |
| 500         | Results  | 184.07           | 1238.45            |
| 1000        | Results  | 355.32           | 1264.62            |

## 4. Analysis of Test Results

![Performance Graphs](../Project2/performance_tests/performance_comparison_graphs.png)
(Figure 1)

Stress tests on the read and write performance of both architectures show a consistent advantage for the HTTPS-based REST system, which outperforms the gRPC implementation in nearly all metrics except for latency at very low user counts (Fig. 1). This outcome is counterintuitive, as gRPC typically offers superior efficiency due to its binary protocol and multiplexed streams.

To investigate the discrepancy, we examined architectural differences that could contribute to the observed slowdown. The gRPC setup uses an older version of PostgreSQL, which may impact query performance. More importantly, this system maintains a live backup instance, introducing additional replication overhead. These factors likely compound under higher loads.

Finally, the gRPC service was set to a `max_workers` value of `10`, likely creating a threading bottleneck, while the REST implementation operates with effectively unbounded asynchronous requests. This limitation likely accounts for the gRPC systemâ€™s elevated latency and reduced throughput as concurrency increases.

## 5. AI Usage

### 5.1 REST HTTPS Based Architecture

To develop the REST HTTPS Based architecture we made liberal use of AI through a coding agent, Cursor. Using pre-existing domain knowledge, we sketched out a system plan that outlined a general architecture, libraries we wanted to use, and the general project requirements. This outline was provided to the LLM and formalized into a more comprehensive plan of action.

From there, a pair-programming paradigm was adopted, where we would request the LLM to make changes to the code base, and then we would review the changes and approve, edit, or deny them and implement things manually.

Initially the AI agent tended to over-engineer and add features that were not requested or were beyond the scope of the assignment. Manual refactoring was done to simplify the codebase and we updated our prompting strategy to ensure the model produced simple output suitable for this class project.

The evaluation scripts were generated by the coding agent as well.

### 5.2 RPC Microservice Architecture

## 6. Distribution of Workload

We collaborated initially on coming up with different system designs suitable for the project. Once two concepts were decided on, we worked largely indepedently. Adam developed the REST architecture and John took on the Microservice architecture. Finally, we merged our changes into the git repository and worked together on the evaluation section and the report.
